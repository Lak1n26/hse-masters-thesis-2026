{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT4Rec Model Training and Evaluation\n",
    "\n",
    "Bidirectional Encoder Representations from Transformers for Sequential Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.11.14 (main, Oct 28 2025, 12:11:54) [Clang 20.1.4 ]\n",
      "Pandas version: 2.3.3\n",
      "Numpy version: 1.26.4\n",
      "PyTorch version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "# Fix for MPS (Apple Silicon) - disable MPS to avoid float64 issues\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.set_default_device('cpu')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.dataset import Dataset\n",
    "from rectools.models import BERT4RecModel\n",
    "from rectools.models.nn.item_net import IdEmbeddingsItemNet, CatFeaturesItemNet\n",
    "\n",
    "from tecd_retail_recsys.data import DataPreprocessor\n",
    "from tecd_retail_recsys.metrics import calculate_metrics\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BERT4Rec\n",
      "Number of transformer blocks: 2\n",
      "Number of attention heads: 4\n",
      "Latent factors (n_factors): 256\n",
      "Dropout rate: 0.2\n",
      "Mask probability: 0.15\n",
      "Session max length: 130\n",
      "Loss: softmax\n",
      "Number of negatives: 1\n",
      "Batch size: 256\n",
      "Epochs: 100\n",
      "Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "with open('configs/bert4rec.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Model parameters\n",
    "N_BLOCKS = config['model']['n_blocks']\n",
    "N_HEADS = config['model']['n_heads']\n",
    "N_FACTORS = config['model']['n_factors']\n",
    "DROPOUT_RATE = config['model']['dropout_rate']\n",
    "MASK_PROB = config['model']['mask_prob']\n",
    "SESSION_MAX_LEN = config['model']['session_max_len']\n",
    "TRAIN_MIN_USER_INTERACTIONS = config['model']['train_min_user_interactions']\n",
    "USE_POS_EMB = config['model']['use_pos_emb']\n",
    "USE_KEY_PADDING_MASK = config['model']['use_key_padding_mask']\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = config['train']['batch_size']\n",
    "EPOCHS = config['train']['epochs']\n",
    "LEARNING_RATE = config['train']['learning_rate']\n",
    "LOSS = config['train']['loss']\n",
    "N_NEGATIVES = config['train']['n_negatives']\n",
    "GBCE_T = config['train']['gbce_t']\n",
    "DETERMINISTIC = config['train']['deterministic']\n",
    "VERBOSE = config['train']['verbose']\n",
    "DATALOADER_NUM_WORKERS = config['train']['dataloader_num_workers']\n",
    "TOP_K = config['train']['top_k']\n",
    "\n",
    "# Info parameters\n",
    "MODEL_DIR = config['info']['MODEL_DIR']\n",
    "METRICS = config['info']['metrics']\n",
    "SAVE_MODEL = config['info']['save_model']\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Enable deterministic behaviour\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "except TypeError:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "try:\n",
    "    seed_everything(SEED, workers=True)\n",
    "except TypeError:\n",
    "    seed_everything(SEED)\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Model: BERT4Rec\")\n",
    "print(f\"Number of transformer blocks: {N_BLOCKS}\")\n",
    "print(f\"Number of attention heads: {N_HEADS}\")\n",
    "print(f\"Latent factors (n_factors): {N_FACTORS}\")\n",
    "print(f\"Dropout rate: {DROPOUT_RATE}\")\n",
    "print(f\"Mask probability: {MASK_PROB}\")\n",
    "print(f\"Session max length: {SESSION_MAX_LEN}\")\n",
    "print(f\"Loss: {LOSS}\")\n",
    "print(f\"Number of negatives: {N_NEGATIVES}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Loading events from t_ecd_small_partial/dataset/small/retail/events\n",
      "Loaded 236,479,226 total events\n",
      "Loading items data from t_ecd_small_partial/dataset/small/retail/items.pq\n",
      "Loaded 250,171 items with features: ['item_id', 'item_brand_id', 'item_category', 'item_subcategory', 'item_price', 'item_embedding']\n",
      "Merged item features. Data shape: (236479226, 12)\n",
      "Filtered to 3,758,762 events with action_type='added-to-cart'\n",
      "After filtering (min_user_interactions=1, min_item_interactions=20): 3,249,972 events, 84,944 users, 30,954 items\n",
      "Created mappings: 84944 users, 30954 items\n",
      "Temporal split - Train: days < 1269 (902,543 events), Val: days 1269-1288 (228,339 events), Test: days >= 1289 (223,395 events)\n",
      "Users in each part (train, val, test) - 7425\n",
      "Train shape: (902543, 12)\n",
      "Val shape: (228339, 12)\n",
      "Test shape: (223395, 12)\n",
      "Number of users: 7425\n",
      "Number of items: 30751\n"
     ]
    }
   ],
   "source": [
    "dp = DataPreprocessor(\n",
    "    day_begin=1082, \n",
    "    day_end=1308, \n",
    "    val_days=20, \n",
    "    test_days=20, \n",
    "    min_user_interactions=1, \n",
    "    min_item_interactions=20\n",
    ")\n",
    "train_df, val_df, test_df = dp.preprocess()\n",
    "\n",
    "train_orig = train_df.copy()\n",
    "val_orig = val_df.copy()\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Val shape: {val_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Number of users: {train_df['user_id'].nunique()}\")\n",
    "print(f\"Number of items: {train_df['item_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare RecTools Dataset\n",
    "\n",
    "RecTools requires data in specific format with interactions and optional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions shape: (902543, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>79038</td>\n",
       "      <td>20358</td>\n",
       "      <td>93485160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>44584</td>\n",
       "      <td>23489</td>\n",
       "      <td>93485187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>12869</td>\n",
       "      <td>2908</td>\n",
       "      <td>93485221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>42145</td>\n",
       "      <td>18904</td>\n",
       "      <td>93485421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>15304</td>\n",
       "      <td>14462</td>\n",
       "      <td>93485437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  datetime  weight\n",
       "1252    79038    20358  93485160       1\n",
       "1336    44584    23489  93485187       1\n",
       "1453    12869     2908  93485221       1\n",
       "2144    42145    18904  93485421       1\n",
       "2189    15304    14462  93485437       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare interactions for training\n",
    "interactions_train = train_df[['user_id', 'item_id', 'timestamp']].copy()\n",
    "interactions_train.columns = [Columns.User, Columns.Item, Columns.Datetime]\n",
    "interactions_train[Columns.Weight] = 1\n",
    "\n",
    "print(f\"Train interactions shape: {interactions_train.shape}\")\n",
    "interactions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val interactions shape: (228339, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173756285</th>\n",
       "      <td>40764</td>\n",
       "      <td>15800</td>\n",
       "      <td>109641615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173756680</th>\n",
       "      <td>52328</td>\n",
       "      <td>26142</td>\n",
       "      <td>109641663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173757269</th>\n",
       "      <td>21228</td>\n",
       "      <td>17027</td>\n",
       "      <td>109641733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173757315</th>\n",
       "      <td>29325</td>\n",
       "      <td>24210</td>\n",
       "      <td>109641741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173757516</th>\n",
       "      <td>22801</td>\n",
       "      <td>20587</td>\n",
       "      <td>109641767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  item_id   datetime  weight\n",
       "173756285    40764    15800  109641615       1\n",
       "173756680    52328    26142  109641663       1\n",
       "173757269    21228    17027  109641733       1\n",
       "173757315    29325    24210  109641741       1\n",
       "173757516    22801    20587  109641767       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare validation interactions\n",
    "interactions_val = val_df[['user_id', 'item_id', 'timestamp']].copy()\n",
    "interactions_val.columns = [Columns.User, Columns.Item, Columns.Datetime]\n",
    "interactions_val[Columns.Weight] = 1\n",
    "\n",
    "print(f\"Val interactions shape: {interactions_val.shape}\")\n",
    "interactions_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features shape: (91149, 3)\n",
      "Features: ['brand' 'category' 'subcategory']\n"
     ]
    }
   ],
   "source": [
    "# Prepare item features (categorical)\n",
    "item_features_list = []\n",
    "\n",
    "# Brand feature\n",
    "if 'item_brand_id' in train_df.columns:\n",
    "    brand_feature = train_df[['item_id', 'item_brand_id']].drop_duplicates()\n",
    "    brand_feature.columns = ['id', 'value']\n",
    "    brand_feature['feature'] = 'brand'\n",
    "    brand_feature = brand_feature[brand_feature['value'].notna()]\n",
    "    item_features_list.append(brand_feature)\n",
    "\n",
    "# Category feature\n",
    "if 'item_category' in train_df.columns:\n",
    "    category_feature = train_df[['item_id', 'item_category']].drop_duplicates()\n",
    "    category_feature.columns = ['id', 'value']\n",
    "    category_feature['feature'] = 'category'\n",
    "    category_feature = category_feature[category_feature['value'].notna()]\n",
    "    item_features_list.append(category_feature)\n",
    "\n",
    "# Subcategory feature\n",
    "if 'item_subcategory' in train_df.columns:\n",
    "    subcategory_feature = train_df[['item_id', 'item_subcategory']].drop_duplicates()\n",
    "    subcategory_feature.columns = ['id', 'value']\n",
    "    subcategory_feature['feature'] = 'subcategory'\n",
    "    subcategory_feature = subcategory_feature[subcategory_feature['value'].notna()]\n",
    "    item_features_list.append(subcategory_feature)\n",
    "\n",
    "if item_features_list:\n",
    "    item_features = pd.concat(item_features_list, ignore_index=True)\n",
    "    print(f\"Item features shape: {item_features.shape}\")\n",
    "    print(f\"Features: {item_features['feature'].unique()}\")\n",
    "    item_features.head()\n",
    "else:\n",
    "    item_features = None\n",
    "    print(\"No item features available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created successfully\n",
      "Users: 7425\n",
      "Items: 30751\n",
      "Interactions: 902543\n"
     ]
    }
   ],
   "source": [
    "# Construct RecTools dataset\n",
    "if item_features is not None:\n",
    "    dataset = Dataset.construct(\n",
    "        interactions_df=interactions_train,\n",
    "        item_features_df=item_features,\n",
    "        cat_item_features=['brand', 'category', 'subcategory']\n",
    "    )\n",
    "else:\n",
    "    dataset = Dataset.construct(\n",
    "        interactions_df=interactions_train\n",
    "    )\n",
    "\n",
    "print(f\"Dataset created successfully\")\n",
    "print(f\"Users: {dataset.user_id_map.size}\")\n",
    "print(f\"Items: {dataset.item_id_map.size}\")\n",
    "print(f\"Interactions: {dataset.interactions.df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom trainer function to force CPU usage (avoid MPS float64 issues)\n",
    "def get_cpu_trainer(**kwargs):\n",
    "    # Force CPU\n",
    "    from pytorch_lightning import Trainer\n",
    "    trainer_kwargs = {\n",
    "        'accelerator': 'cpu',\n",
    "        'devices': 1,\n",
    "        'max_epochs': EPOCHS,\n",
    "    }\n",
    "    trainer_kwargs.update(kwargs)\n",
    "    return Trainer(**trainer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT4Rec model initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT4Rec model\n",
    "\n",
    "if item_features is not None:\n",
    "    # Use both item IDs and categorical features\n",
    "    item_net_block_types = (IdEmbeddingsItemNet, CatFeaturesItemNet)\n",
    "else:\n",
    "    # Use only item IDs\n",
    "    item_net_block_types = (IdEmbeddingsItemNet,)\n",
    "\n",
    "model = BERT4RecModel(\n",
    "    n_blocks=N_BLOCKS,\n",
    "    n_heads=N_HEADS,\n",
    "    n_factors=N_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    mask_prob=MASK_PROB,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    loss=LOSS,\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    gbce_t=GBCE_T,\n",
    "    lr=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    deterministic=DETERMINISTIC,\n",
    "    verbose=VERBOSE,\n",
    "    dataloader_num_workers=DATALOADER_NUM_WORKERS,\n",
    "    use_pos_emb=USE_POS_EMB,\n",
    "    use_key_padding_mask=USE_KEY_PADDING_MASK,\n",
    "    item_net_block_types=item_net_block_types,\n",
    "    recommend_torch_device='cpu',  # Force CPU to avoid MPS float64 issues\n",
    "    # get_trainer_func=get_cpu_trainer,  # Use custom trainer with CPU\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"BERT4Rec model initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type                     | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | torch_model | TransformerTorchBackbone | 9.4 M  | train\n",
      "-----------------------------------------------------------------\n",
      "9.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.4 M     Total params\n",
      "37.783    Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e122a62c59c409c8c9f33096376d363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 1.92 s, total: 3.09 s\n",
      "Wall time: 3.83 s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:344\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    343\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1328\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1304\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1305\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1306\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1326\u001b[39m \n\u001b[32m   1327\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:526\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/torch/optim/adam.py:227\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:124\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/nn/transformers/lightning.py:320\u001b[39m, in \u001b[36mTransformerLightningModule.training_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    318\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m._calc_custom_loss(batch, batch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_loss_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/core/module.py:521\u001b[39m, in \u001b[36mLightningModule.log\u001b[39m\u001b[34m(self, name, value, prog_bar, logger, on_step, on_epoch, reduce_fx, enable_graph, sync_dist, sync_dist_group, add_dataloader_idx, batch_size, metric_attribute, rank_zero_only)\u001b[39m\n\u001b[32m    519\u001b[39m     logger = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_current_fx_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduce_fx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduce_fx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_dataloader_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_dataloader_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_dist\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_dist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_accelerator_connector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_distributed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_dist_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_dist_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_dist_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_attribute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_attribute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrank_zero_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank_zero_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m trainer._logger_connector._current_fx = \u001b[38;5;28mself\u001b[39m._current_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:1181\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1180\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:413\u001b[39m, in \u001b[36m_ResultCollection.log\u001b[39m\u001b[34m(self, fx, name, value, prog_bar, logger, on_step, on_epoch, reduce_fx, enable_graph, sync_dist, sync_dist_fn, sync_dist_group, add_dataloader_idx, batch_size, metric_attribute, rank_zero_only)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[32m    411\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou called `self.log(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ...)` twice in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` with different arguments. This is not allowed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m batch_size = \u001b[38;5;28mself\u001b[39m._extract_batch_size(\u001b[38;5;28mself\u001b[39m[key], batch_size, meta)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:309\u001b[39m, in \u001b[36m_ResultMetric.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m d = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m.update(\u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetric\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove_data_to_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:78\u001b[39m, in \u001b[36mapply_to_collection\u001b[39m\u001b[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# slow path for everything else\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_to_collection_slow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_frozen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_frozen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:154\u001b[39m, in \u001b[36m_apply_to_collection_slow\u001b[39m\u001b[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data.items():\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     v = \u001b[43m_apply_to_collection_slow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_frozen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_frozen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_none \u001b[38;5;129;01mor\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:154\u001b[39m, in \u001b[36m_apply_to_collection_slow\u001b[39m\u001b[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data.items():\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     v = \u001b[43m_apply_to_collection_slow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrong_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_frozen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_frozen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_none \u001b[38;5;129;01mor\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:102\u001b[39m, in \u001b[36m_apply_to_collection_slow\u001b[39m\u001b[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype) \u001b[38;5;129;01mand\u001b[39;00m (wrong_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m elem_type = \u001b[38;5;28mtype\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_fabric/utilities/apply_func.py:110\u001b[39m, in \u001b[36mmove_data_to_device\u001b[39m\u001b[34m(batch, device)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_TransferableDataType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:70\u001b[39m, in \u001b[36mapply_to_collection\u001b[39m\u001b[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype):  \u001b[38;5;66;03m# single element\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/lightning_fabric/utilities/apply_func.py:104\u001b[39m, in \u001b[36mmove_data_to_device.<locals>.batch_to\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    103\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mnon_blocking\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m data_output = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/torch/utils/_device.py:109\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m# Train the model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mmodel.fit(dataset)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining completed!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2572\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2571\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1447\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1411\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1409\u001b[39m st = clock2()\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/base.py:339\u001b[39m, in \u001b[36mModelBase.fit\u001b[39m\u001b[34m(self, dataset, *args, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dataset: Dataset, *args: tp.Any, **kwargs: tp.Any) -> T:\n\u001b[32m    327\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03m    Fit model.\u001b[39;00m\n\u001b[32m    329\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    337\u001b[39m \u001b[33;03m    self\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m.is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/nn/transformers/base.py:489\u001b[39m, in \u001b[36mTransformerModelBase._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    487\u001b[39m val_dataloader = \u001b[38;5;28mself\u001b[39m.data_preparator.get_dataloader_val()\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m.fit_trainer = deepcopy(\u001b[38;5;28mself\u001b[39m._trainer)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "model.fit(dataset)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.01 ms, sys: 4.42 ms, total: 9.43 ms\n",
      "Wall time: 8.47 ms\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BERT4RecDataPreparator' object has no attribute 'item_id_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m# Get all users from validation set\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mval_users = val_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43muser_id\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m].unique()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrecommendations = model.recommend(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    users=val_users,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dataset=dataset,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    k=TOP_K,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    filter_viewed=False,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    on_unsupported_targets=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrecs_grouped = recommendations.groupby(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43muser_id\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, as_index=False)[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mitem_id\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m].agg(list)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrecs_grouped.columns = [\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43muser_id\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mbert4rec_recs\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrecs_grouped.head()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2572\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2571\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1447\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/IPython/core/magics/execution.py:1411\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1409\u001b[39m st = clock2()\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     exec(code, glob, local_ns)\n\u001b[32m   1412\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:4\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/base.py:471\u001b[39m, in \u001b[36mModelBase.recommend\u001b[39m\u001b[34m(self, users, dataset, k, filter_viewed, items_to_recommend, add_rank_col, on_unsupported_targets, context)\u001b[39m\n\u001b[32m    469\u001b[39m original_user_type = dataset.user_id_map.external_dtype\n\u001b[32m    470\u001b[39m original_item_type = dataset.item_id_map.external_dtype\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_custom_transform_dataset_u2i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_unsupported_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m sorted_item_ids_to_recommend = \u001b[38;5;28mself\u001b[39m._get_sorted_item_ids_to_recommend(items_to_recommend, dataset)\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# Here for hot and warm we get internal ids, for cold we keep external ids\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/nn/transformers/base.py:498\u001b[39m, in \u001b[36mTransformerModelBase._custom_transform_dataset_u2i\u001b[39m\u001b[34m(self, dataset, users, on_unsupported_targets, context)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_custom_transform_dataset_u2i\u001b[39m(\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    493\u001b[39m     dataset: Dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    496\u001b[39m     context: tp.Optional[pd.DataFrame] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    497\u001b[39m ) -> Dataset:\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_preparator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform_dataset_u2i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/nn/transformers/data_preparator.py:391\u001b[39m, in \u001b[36mTransformerDataPreparatorBase.transform_dataset_u2i\u001b[39m\u001b[34m(self, dataset, users, context)\u001b[39m\n\u001b[32m    389\u001b[39m interactions = dataset.interactions.df[required_cols]\n\u001b[32m    390\u001b[39m users_internal = dataset.user_id_map.convert_to_internal(users, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m items_internal = dataset.item_id_map.convert_to_internal(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_known_item_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    392\u001b[39m interactions = interactions[interactions[Columns.User].isin(users_internal)]\n\u001b[32m    393\u001b[39m interactions = interactions[interactions[Columns.Item].isin(items_internal)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/git_projects/hse-masters-thesis-2026/.venv/lib/python3.11/site-packages/rectools/models/nn/transformers/data_preparator.py:180\u001b[39m, in \u001b[36mTransformerDataPreparatorBase.get_known_item_ids\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_known_item_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m    179\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return external item ids from processed dataset in sorted order.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mitem_id_map\u001b[49m.get_external_sorted_by_internal()[\u001b[38;5;28mself\u001b[39m.n_item_extra_tokens :]\n",
      "\u001b[31mAttributeError\u001b[39m: 'BERT4RecDataPreparator' object has no attribute 'item_id_map'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get all users from validation set\n",
    "val_users = val_df['user_id'].unique()\n",
    "\n",
    "recommendations = model.recommend(\n",
    "    users=val_users,\n",
    "    dataset=dataset,\n",
    "    k=TOP_K,\n",
    "    filter_viewed=False,\n",
    "    on_unsupported_targets=\"ignore\"\n",
    ")\n",
    "\n",
    "recs_grouped = recommendations.groupby('user_id', as_index=False)['item_id'].agg(list)\n",
    "recs_grouped.columns = ['user_id', 'bert4rec_recs']\n",
    "recs_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataframe shape: (7425, 6)\n",
      "Users with recommendations: 7425\n"
     ]
    }
   ],
   "source": [
    "joined = dp.get_grouped_data(train_orig, val_orig, test_df)\n",
    "joined['train_val_interactions'] = joined['train_interactions'] + joined['val_interactions']\n",
    "\n",
    "evaluation_df = joined.merge(\n",
    "    recs_grouped, \n",
    "    on='user_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill users without recommendations with empty lists\n",
    "evaluation_df['bert4rec_recs'] = evaluation_df['bert4rec_recs'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "print(f\"Evaluation dataframe shape: {evaluation_df.shape}\")\n",
    "print(f\"Users with recommendations: {(evaluation_df['bert4rec_recs'].str.len() > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Metrics debug] resolved gt_col='val_interactions' item_id_index=0\n",
      "[Metrics debug] ratings_true shape: (228339, 3) ratings_pred shape: (742500, 3)\n",
      "  ratings_true dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  ratings_pred dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  user_id=11 gt_count=22 pred_count=100 overlap=2\n",
      "  user_id=14 gt_count=5 pred_count=100 overlap=0\n",
      "    [ID spaces] gt sample=[9341, 16732, 17585, 28024, 30789] range=[9341, 30789] | rec sample=[83, 153, 394, 415, 520] range=[83, 30642]\n",
      "  user_id=21 gt_count=47 pred_count=100 overlap=10\n",
      "\n",
      "At k=10:\n",
      "  MAP@10       = 0.1063\n",
      "  NDCG@10      = 0.2692\n",
      "  Precision@10 = 0.1301\n",
      "  Recall@10    = 0.0396\n",
      "\n",
      "At k=100:\n",
      "  MAP@100       = 0.0409\n",
      "  NDCG@100      = 0.1772\n",
      "  Precision@100 = 0.0466\n",
      "  Recall@100    = 0.1407\n",
      "\n",
      "Other Metrics:\n",
      "  MRR                 = 0.2481\n",
      "  Catalog Coverage    = 0.2301\n",
      "  Diversity     = 0.9859  [0=same recs for all, 1=unique recs]\n",
      "  Novelty             = 0.7915\n",
      "  Serendipity         = 0.0360\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "metrics_result = calculate_metrics(\n",
    "    evaluation_df,\n",
    "    train_col='train_interactions',\n",
    "    gt_col='val_interactions',\n",
    "    model_preds='bert4rec_recs',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models/bert4rec/bert4rec_model\n",
      "Recommendations saved to ./models/bert4rec/recommendations.parquet\n",
      "Full recommendations saved to ./models/bert4rec/recommendations_full.parquet\n"
     ]
    }
   ],
   "source": [
    "if SAVE_MODEL:\n",
    "    # Save model\n",
    "    model_path = os.path.join(MODEL_DIR, \"bert4rec_model\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Save recommendations\n",
    "    recs_path = os.path.join(MODEL_DIR, \"recommendations.parquet\")\n",
    "    recs_grouped.to_parquet(recs_path, index=False)\n",
    "    print(f\"Recommendations saved to {recs_path}\")\n",
    "    \n",
    "    # Save full recommendations with scores\n",
    "    recs_full_path = os.path.join(MODEL_DIR, \"recommendations_full.parquet\")\n",
    "    recommendations.to_parquet(recs_full_path, index=False)\n",
    "    print(f\"Full recommendations saved to {recs_full_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <style>\n",
    "        table {\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        th {\n",
    "            background-color: #2196F3;\n",
    "            color: white;\n",
    "            padding: 12px;\n",
    "            text-align: left;\n",
    "            border: 1px solid #ddd;\n",
    "            font-size: 13px;\n",
    "        }\n",
    "        td {\n",
    "            padding: 10px;\n",
    "            border: 1px solid #ddd;\n",
    "            text-align: left;\n",
    "            font-size: 12px;\n",
    "        }\n",
    "        tr:nth-child(even) {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "        tr:hover {\n",
    "            background-color: #ddd;\n",
    "        }\n",
    "        .best {\n",
    "            background-color: #c8e6c9 !important;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .worst {\n",
    "            background-color: #ffcdd2 !important;\n",
    "        }\n",
    "        .good {\n",
    "            background-color: #e8f5e9 !important;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h2>BERT4Rec: </h2>\n",
    "    <table>\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th></th>\n",
    "                <th>n_blocks</th>\n",
    "                <th>n_heads</th>\n",
    "                <th>n_factors</th>\n",
    "                <th>dropout_rate</th>\n",
    "                <th>mask_prob</th>\n",
    "                <th>session_max_len</th>\n",
    "                <th>batch_size</th>\n",
    "                <th>learning_rate</th>\n",
    "                <th>loss</th>\n",
    "                <th>n_negatives</th>\n",
    "                <th>epochs</th>\n",
    "                <th>NDCG@100</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>1</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>256</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>50</td>\n",
    "                <td>128</td>\n",
    "                <td>0.001</td>\n",
    "                <td>softmax</td>\n",
    "                <td>1</td>\n",
    "                <td>100</td>\n",
    "                <td>0.2581</td>\n",
    "            </tr>\n",
    "            <tr class=\"worst\">\n",
    "                <td>2</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>256</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>50</td>\n",
    "                <td>128</td>\n",
    "                <td>0.001</td>\n",
    "                <td>gBCE</td>\n",
    "                <td>50</td>\n",
    "                <td>100</td>\n",
    "                <td>0.2190</td>\n",
    "            </tr>\n",
    "            <tr class=\"best\">\n",
    "                <td>3</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>256</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>100</td>\n",
    "                <td>128</td>\n",
    "                <td>0.001</td>\n",
    "                <td>softmax</td>\n",
    "                <td>1</td>\n",
    "                <td>100</td>\n",
    "                <td><strong>0.2726</strong></td>\n",
    "            </tr>\n",
    "            <tr class=\"good\">\n",
    "                <td>4</td>\n",
    "                <td>3</td>\n",
    "                <td>8</td>\n",
    "                <td>512</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>100</td>\n",
    "                <td>128</td>\n",
    "                <td>0.001</td>\n",
    "                <td>softmax</td>\n",
    "                <td>1</td>\n",
    "                <td>100</td>\n",
    "                <td>0.2661</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>5</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>256</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>100</td>\n",
    "                <td>256</td>\n",
    "                <td>0.001</td>\n",
    "                <td>sampled_softmax</td>\n",
    "                <td>100</td>\n",
    "                <td>100</td>\n",
    "                <td>0.2263</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>6</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>512</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>100</td>\n",
    "                <td>256</td>\n",
    "                <td>0.001</td>\n",
    "                <td>softmax</td>\n",
    "                <td>1</td>\n",
    "                <td>100</td>\n",
    "                <td>0.2331</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>7</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>256</td>\n",
    "                <td>0.1</td>\n",
    "                <td>0.2</td>\n",
    "                <td>100</td>\n",
    "                <td>256</td>\n",
    "                <td>0.0005</td>\n",
    "                <td>softmax</td>\n",
    "                <td>1</td>\n",
    "                <td>150</td>\n",
    "                <td>0.2480</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>8</td>\n",
    "                <td>2</td>\n",
    "                <td>4</td>\n",
    "                <td>256</td>\n",
    "                <td>0.2</td>\n",
    "                <td>0.15</td>\n",
    "                <td>130</td>\n",
    "                <td>256</td>\n",
    "                <td>0.001</td>\n",
    "                <td>softmax</td>\n",
    "                <td>1</td>\n",
    "                <td>100</td>\n",
    "                <td> </td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "    \n",
    "</body>\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
