{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106ea597",
   "metadata": {},
   "source": [
    "### Reciprocal Rank Fusion (RRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5ea913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tecd_retail_recsys.data import DataPreprocessor\n",
    "from tecd_retail_recsys.metrics import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a639ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Loading events from t_ecd_small_partial/dataset/small/retail/events\n",
      "Loaded 236,479,226 total events\n",
      "Loading items data from t_ecd_small_partial/dataset/small/retail/items.pq\n",
      "Loaded 250,171 items with features: ['item_id', 'item_brand_id', 'item_category', 'item_subcategory', 'item_price', 'item_embedding']\n",
      "Merged item features. Data shape: (236479226, 12)\n",
      "Filtered to 3,758,762 events with action_type='added-to-cart'\n",
      "After filtering (min_user_interactions=1, min_item_interactions=20): 3,249,972 events, 84,944 users, 30,954 items\n",
      "Created mappings: 84944 users, 30954 items\n",
      "Temporal split - Train: days < 1269 (902,543 events), Val: days 1269-1288 (228,339 events), Test: days >= 1289 (223,395 events)\n",
      "Users in each part (train, val, test) - 7425\n"
     ]
    }
   ],
   "source": [
    "dp = DataPreprocessor(\n",
    "    day_begin=1082, \n",
    "    day_end=1308, \n",
    "    val_days=20, \n",
    "    test_days=20, \n",
    "    min_user_interactions=1, \n",
    "    min_item_interactions=20\n",
    ")\n",
    "train_df, val_df, test_df = dp.preprocess()\n",
    "trainval_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "\n",
    "joined = dp.get_grouped_data(train_df, val_df, test_df)\n",
    "joined['train_val_interactions'] = joined['train_interactions'] + joined['val_interactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e70435",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = pd.read_parquet(\"models_test/data/all_recs_test.parquet\")\n",
    "model_columns = all_recs.columns[all_recs.columns.str.endswith('_recs')].tolist()\n",
    "for col in model_columns:\n",
    "    if all_recs[col].dtype == 'object':\n",
    "        all_recs[col] = all_recs[col].apply(\n",
    "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9e0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecd_retail_recsys.utils import calculate_avg_prices, calculate_overall_avg_price, get_avg_recs_price, get_item_to_price\n",
    "item_to_price = get_item_to_price(dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687c4b3",
   "metadata": {},
   "source": [
    "#### variant 1 - standart RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60af8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Reciprocal Rank Fusion with k=20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RRF: 100%|██████████| 7425/7425 [00:01<00:00, 6171.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRF recommendations generated for 7425 users\n",
      "[Metrics debug] resolved gt_col='test_interactions' item_id_index=0\n",
      "[Metrics debug] ratings_true shape: (223395, 3) ratings_pred shape: (742500, 3)\n",
      "  ratings_true dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  ratings_pred dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  user_id=11 gt_count=9 pred_count=100 overlap=2\n",
      "  user_id=14 gt_count=56 pred_count=100 overlap=7\n",
      "  user_id=21 gt_count=43 pred_count=100 overlap=14\n",
      "\n",
      "At k=10:\n",
      "  MAP@10       = 0.1927\n",
      "  NDCG@10      = 0.4620\n",
      "  Precision@10 = 0.1970\n",
      "  Recall@10    = 0.0637\n",
      "\n",
      "At k=100:\n",
      "  MAP@100       = 0.0906\n",
      "  NDCG@100      = 0.3161\n",
      "  Precision@100 = 0.0850\n",
      "  Recall@100    = 0.2623\n",
      "\n",
      "Other Metrics:\n",
      "  MRR                 = 0.3078\n",
      "  Catalog Coverage    = 0.9210\n",
      "  Diversity     = 0.9965  [0=same recs for all, 1=unique recs]\n",
      "  Novelty             = 0.7259\n",
      "  Serendipity         = 0.0351\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def reciprocal_rank_fusion(all_recs, model_columns, k=20, top_n=100):\n",
    "    \"\"\"\n",
    "    Объединяет ранжирования через RRF.\n",
    "    \n",
    "    RRF_score(item) = sum_over_models(1 / (k + rank_model(item)))\n",
    "    \n",
    "    Args:\n",
    "        all_recs: DataFrame с рекомендациями моделей\n",
    "        model_columns: список колонок с рекомендациями\n",
    "        k: константа сглаживания\n",
    "        top_n: количество финальных рекомендаций\n",
    "    \"\"\"\n",
    "    print(f\"Computing Reciprocal Rank Fusion with k={k}...\")\n",
    "    \n",
    "    rrf_recommendations = []\n",
    "    \n",
    "    for idx, row in tqdm(all_recs.iterrows(), total=len(all_recs), desc=\"RRF\"):\n",
    "        user_id = row['user_id']\n",
    "        \n",
    "        item_scores = {}\n",
    "        \n",
    "        for model_col in model_columns:\n",
    "            if model_col not in all_recs.columns:\n",
    "                continue\n",
    "                \n",
    "            recs = row[model_col]\n",
    "            \n",
    "            for rank, item_id in enumerate(recs, start=1):\n",
    "                rrf_score = 1.0 / (k + rank)\n",
    "                \n",
    "                if item_id not in item_scores:\n",
    "                    item_scores[item_id] = 0.0\n",
    "                \n",
    "                item_scores[item_id] += rrf_score\n",
    "        \n",
    "        sorted_items = sorted(item_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_items = [item_id for item_id, score in sorted_items[:top_n]]\n",
    "        \n",
    "        rrf_recommendations.append({\n",
    "            'user_id': user_id,\n",
    "            'rrf_recs': top_items\n",
    "        })\n",
    "    \n",
    "    rrf_df = pd.DataFrame(rrf_recommendations)\n",
    "    print(f\"RRF recommendations generated for {len(rrf_df)} users\")\n",
    "    \n",
    "    return rrf_df\n",
    "\n",
    "\n",
    "rrf_recs = reciprocal_rank_fusion(all_recs, model_columns, k=20, top_n=100)\n",
    "\n",
    "\n",
    "evaluation_df_rrf = joined.merge(rrf_recs, on='user_id', how='left')\n",
    "evaluation_df_rrf['rrf_recs'] = evaluation_df_rrf['rrf_recs'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "metrics_rrf = calculate_metrics(\n",
    "    evaluation_df_rrf,\n",
    "    train_col='train_val_interactions',\n",
    "    gt_col='test_interactions',\n",
    "    model_preds='rrf_recs',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4cfd80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя цена рекомендаций модели RRF (v1) на валидации: -3.85\n"
     ]
    }
   ],
   "source": [
    "avg_rrf_recs_price_val = get_avg_recs_price(evaluation_df_rrf, item_to_price, 'rrf_recs')\n",
    "print(f'Средняя цена рекомендаций модели RRF (v1) на валидации: {avg_rrf_recs_price_val:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877eb55c",
   "metadata": {},
   "source": [
    "#### variant 2 - WEIGHTED RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe30efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Weighted RRF with k=20...\n",
      "Model weights: {'bert4rec_recs': 2.0, 'sasrec_recs': 2.0, 'lightfm_recs': 1.5, 'ials_recs': 1.2, 'bivae_recs': 1.0, 'bpr_recs': 1.0, 'tifuknn_recs': 0.8, 'toppersonal_recs': 0.5, 'toppopular_recs': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Weighted RRF: 100%|██████████| 7425/7425 [00:01<00:00, 4921.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# === WEIGHTED RRF ===\n",
    "\n",
    "def weighted_rrf(all_recs, model_columns, model_weights=None, k=20, top_n=100):\n",
    "    \"\"\"\n",
    "    RRF с весами для каждой модели.\n",
    "    Более сильные модели получают больший вес.\n",
    "    \"\"\"\n",
    "    if model_weights is None:\n",
    "        model_weights = {col: 1.0 for col in model_columns}\n",
    "    \n",
    "    print(f\"Computing Weighted RRF with k={k}...\")\n",
    "    print(f\"Model weights: {model_weights}\")\n",
    "    \n",
    "    rrf_recommendations = []\n",
    "    \n",
    "    for idx, row in tqdm(all_recs.iterrows(), total=len(all_recs), desc=\"Weighted RRF\"):\n",
    "        user_id = row['user_id']\n",
    "        item_scores = {}\n",
    "        \n",
    "        for model_col in model_columns:\n",
    "            if model_col not in all_recs.columns:\n",
    "                continue\n",
    "            \n",
    "            weight = model_weights.get(model_col, 1.0)\n",
    "            recs = row[model_col]\n",
    "            \n",
    "            for rank, item_id in enumerate(recs, start=1):\n",
    "                # Взвешенный RRF скор\n",
    "                rrf_score = weight / (k + rank)\n",
    "                \n",
    "                if item_id not in item_scores:\n",
    "                    item_scores[item_id] = 0.0\n",
    "                \n",
    "                item_scores[item_id] += rrf_score\n",
    "        \n",
    "        # Сортируем и берем топ-N\n",
    "        sorted_items = sorted(item_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_items = [item_id for item_id, score in sorted_items[:top_n]]\n",
    "        \n",
    "        rrf_recommendations.append({\n",
    "            'user_id': user_id,\n",
    "            'rrf_weighted_recs': top_items\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rrf_recommendations)\n",
    "\n",
    "\n",
    "# случайные веса\n",
    "model_weights = {\n",
    "    'bert4rec_recs': 2.0,\n",
    "    'sasrec_recs': 2.0,\n",
    "    'lightfm_recs': 1.5,\n",
    "    'ials_recs': 1.2,\n",
    "    'bivae_recs': 1.0,\n",
    "    'bpr_recs': 1.0,\n",
    "    'tifuknn_recs': 0.8,\n",
    "    'toppersonal_recs': 0.5,\n",
    "    'toppopular_recs': 0.3,\n",
    "}\n",
    "\n",
    "rrf_weighted = weighted_rrf(all_recs, model_columns, model_weights, k=20, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11148e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Metrics debug] resolved gt_col='test_interactions' item_id_index=0\n",
      "[Metrics debug] ratings_true shape: (223395, 3) ratings_pred shape: (742500, 3)\n",
      "  ratings_true dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  ratings_pred dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  user_id=11 gt_count=9 pred_count=100 overlap=2\n",
      "  user_id=14 gt_count=56 pred_count=100 overlap=6\n",
      "  user_id=21 gt_count=43 pred_count=100 overlap=14\n",
      "\n",
      "At k=10:\n",
      "  MAP@10       = 0.2342\n",
      "  NDCG@10      = 0.5307\n",
      "  Precision@10 = 0.2166\n",
      "  Recall@10    = 0.0724\n",
      "\n",
      "At k=100:\n",
      "  MAP@100       = 0.0968\n",
      "  NDCG@100      = 0.3194\n",
      "  Precision@100 = 0.0793\n",
      "  Recall@100    = 0.2473\n",
      "\n",
      "Other Metrics:\n",
      "  MRR                 = 0.3220\n",
      "  Catalog Coverage    = 0.8963\n",
      "  Diversity     = 0.9964  [0=same recs for all, 1=unique recs]\n",
      "  Novelty             = 0.7932\n",
      "  Serendipity         = 0.0306\n"
     ]
    }
   ],
   "source": [
    "evaluation_df_rrf = joined.merge(rrf_weighted, on='user_id', how='left')\n",
    "evaluation_df_rrf['rrf_weighted_recs'] = evaluation_df_rrf['rrf_weighted_recs'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "metrics_rrf = calculate_metrics(\n",
    "    evaluation_df_rrf,\n",
    "    train_col='train_val_interactions',\n",
    "    gt_col='test_interactions',\n",
    "    model_preds='rrf_weighted_recs',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd78d041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Weighted RRF with k=20...\n",
      "Model weights: {'bert4rec_recs': 0.2774, 'sasrec_recs': 0.159, 'lightfm_recs': 0.2218, 'ials_recs': 0.0645, 'bivae_recs': 0.162, 'bpr_recs': 0.1956, 'tifuknn_recs': 0.0752, 'toppersonal_recs': 0.3455, 'toppopular_recs': 0.0891}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Weighted RRF: 100%|██████████| 7425/7425 [00:01<00:00, 6142.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# выставим корректные веса\n",
    "# вес модели == ndcg@100 отдельной модели на валидации в отдельности\n",
    "correct_model_weights = {\n",
    "    'bert4rec_recs': 0.2774,\n",
    "    'sasrec_recs': 0.1590,\n",
    "    'lightfm_recs': 0.2218,\n",
    "    'ials_recs': 0.0645,\n",
    "    'bivae_recs': 0.162,\n",
    "    'bpr_recs': 0.1956,\n",
    "    'tifuknn_recs': 0.0752,\n",
    "    'toppersonal_recs': 0.3455,\n",
    "    'toppopular_recs': 0.0891,\n",
    "}\n",
    "\n",
    "rrf_weighted = weighted_rrf(all_recs, model_columns, correct_model_weights, k=20, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfd2f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Metrics debug] resolved gt_col='test_interactions' item_id_index=0\n",
      "[Metrics debug] ratings_true shape: (223395, 3) ratings_pred shape: (742500, 3)\n",
      "  ratings_true dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  ratings_pred dtypes: {'user_id': dtype('int64'), 'item_id': dtype('int64')}\n",
      "  user_id=11 gt_count=9 pred_count=100 overlap=2\n",
      "  user_id=14 gt_count=56 pred_count=100 overlap=6\n",
      "  user_id=21 gt_count=43 pred_count=100 overlap=12\n",
      "\n",
      "At k=10:\n",
      "  MAP@10       = 0.3491\n",
      "  NDCG@10      = 0.7018\n",
      "  Precision@10 = 0.2824\n",
      "  Recall@10    = 0.0927\n",
      "\n",
      "At k=100:\n",
      "  MAP@100       = 0.1330\n",
      "  NDCG@100      = 0.3779\n",
      "  Precision@100 = 0.0902\n",
      "  Recall@100    = 0.2727\n",
      "\n",
      "Other Metrics:\n",
      "  MRR                 = 0.3832\n",
      "  Catalog Coverage    = 0.9701\n",
      "  Diversity     = 0.9967  [0=same recs for all, 1=unique recs]\n",
      "  Novelty             = 0.7657\n",
      "  Serendipity         = 0.0214\n"
     ]
    }
   ],
   "source": [
    "evaluation_df_rrf = joined.merge(rrf_weighted, on='user_id', how='left')\n",
    "evaluation_df_rrf['rrf_weighted_recs'] = evaluation_df_rrf['rrf_weighted_recs'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "metrics_rrf = calculate_metrics(\n",
    "    evaluation_df_rrf,\n",
    "    train_col='train_val_interactions',\n",
    "    gt_col='test_interactions',\n",
    "    model_preds='rrf_weighted_recs',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c550287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя цена рекомендаций модели RRF (v2) на валидации: -3.85\n"
     ]
    }
   ],
   "source": [
    "avg_rrf_recs_price_val = get_avg_recs_price(evaluation_df_rrf, item_to_price, 'rrf_weighted_recs')\n",
    "print(f'Средняя цена рекомендаций модели RRF (v2) на валидации: {avg_rrf_recs_price_val:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298dad4",
   "metadata": {},
   "source": [
    "```\n",
    "Удалось наконец-то побить результат модели TopPersonal на тестовой выборке (0.3752)!\n",
    "NDCG@100 с использованием взвешенного RRF = 0.3779.\n",
    "\n",
    "Novelty=0.77 говорит о том, что есть хороший баланс между популярными товарами и новизной.\n",
    "Serendipity в 0.02 говорит о том, что 2% рекомендаций оказываются неожиданными и релевантными, в то время как у модели TopPersonal Serendipity равняется нулю.\n",
    "\n",
    "Средняя цена рекомендаций модели при этом увеличилась незначительно (на 0.01).\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
